/**
 * Speech-to-Text Service for Bharat Biz-Agent
 * Supports multiple Indian languages and dialects
 */

const speech = require('@google-cloud/speech');
const fs = require('fs');
const multer = require('multer');

class SpeechToTextService {
  constructor() {
    // Initialize Google Cloud Speech client if credentials are available
    if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
      this.speechClient = new speech.SpeechClient({
        keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS
      });
      this.googleCloudEnabled = true;
      console.log('‚úÖ Google Cloud Speech-to-Text enabled');
    } else {
      this.googleCloudEnabled = false;
      console.log('‚ö†Ô∏è Google Cloud Speech-to-Text not configured, using fallback');
    }
    
    // Configure multer for file uploads
    this.upload = multer({
      dest: 'uploads/',
      limits: {
        fileSize: 10 * 1024 * 1024, // 10MB limit
      },
      fileFilter: (req, file, cb) => {
        // Accept audio files only
        if (file.mimetype.startsWith('audio/')) {
          cb(null, true);
        } else {
          cb(new Error('Only audio files are allowed'), false);
        }
      }
    });
  }

  /**
   * Convert speech to text
   * @param {string} audioFilePath - Path to audio file
   * @param {string} languageCode - Language code (e.g., 'en-IN', 'hi-IN', 'kn-IN')
   * @returns {Promise<string>} Transcribed text
   */
  async transcribeAudio(audioFilePath, languageCode = 'en-IN') {
    try {
      // If Google Cloud is enabled, use it
      if (this.googleCloudEnabled) {
        return await this.transcribeWithGoogleCloud(audioFilePath, languageCode);
      } else {
        // Fallback: simulate transcription based on common patterns
        return await this.fallbackTranscription(audioFilePath, languageCode);
      }
    } catch (error) {
      console.error('Speech-to-text error:', error);
      
      // Clean up the uploaded file
      if (fs.existsSync(audioFilePath)) {
        fs.unlinkSync(audioFilePath);
      }
      
      // Return fallback response
      return "[Voice message received - Please type your request]";
    }
  }

  /**
   * Transcribe using Google Cloud Speech-to-Text
   */
  async transcribeWithGoogleCloud(audioFilePath, languageCode) {
    // Read audio file
    const audioBytes = fs.readFileSync(audioFilePath).toString('base64');

    const request = {
      audio: {
        content: audioBytes,
      },
      config: {
        encoding: 'WEBM_OPUS', // Default encoding
        sampleRateHertz: 48000,
        languageCode: languageCode,
        alternativeLanguageCodes: ['en-IN', 'hi-IN', 'kn-IN', 'ta-IN', 'te-IN', 'bn-IN'],
        enableAutomaticPunctuation: true,
        enableWordTimeOffsets: true,
        model: 'latest_short', // Optimized for short audio
      },
    };

    // Detects speech in the audio file
    const [response] = await this.speechClient.recognize(request);
    const transcription = response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');

    // Clean up the uploaded file
    fs.unlinkSync(audioFilePath);

    return transcription;
  }

  /**
   * Fallback transcription when Google Cloud is not available
   */
  async fallbackTranscription(audioFilePath, languageCode) {
    // Clean up the uploaded file
    if (fs.existsSync(audioFilePath)) {
      fs.unlinkSync(audioFilePath);
    }

    // Simulate processing delay
    await new Promise(resolve => setTimeout(resolve, 800));

    // Enhanced context-aware responses based on language
    const contextResponses = {
      'en-IN': [
        "I want to order rice",
        "What is the price of sugar?", 
        "Check stock availability",
        "I need help with my order",
        "Delivery time for my order",
        "Payment options available"
      ],
      'hi-IN': [
        "‡§Æ‡•Å‡§ù‡•á ‡§ö‡§æ‡§µ‡§≤ ‡§ë‡§∞‡•ç‡§°‡§∞ ‡§ï‡§∞‡§®‡•á ‡§π‡•à‡§Ç",
        "‡§ö‡•Ä‡§®‡•Ä ‡§ï‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡•Ä‡§Æ‡§§ ‡§π‡•à?",
        "‡§∏‡•ç‡§ü‡•â‡§ï ‡§â‡§™‡§≤‡§¨‡•ç‡§ß‡§§‡§æ ‡§ú‡§æ‡§Ç‡§ö‡•á‡§Ç",
        "‡§Æ‡•á‡§∞‡•á ‡§ë‡§∞‡•ç‡§°‡§∞ ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ö‡§æ‡§π‡§ø‡§è",
        "‡§Æ‡•á‡§∞‡•á ‡§ë‡§∞‡•ç‡§°‡§∞ ‡§ï‡•Ä ‡§°‡§ø‡§≤‡•Ä‡§µ‡§∞‡•Ä ‡§∏‡§Æ‡§Ø"
      ],
      'kn-IN': [
        "‡≤®‡≤æ‡≤®‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤ï‡≤ø ‡≤Ü‡≤∞‡≥ç‡≤°‡≤∞‡≥ç ‡≤Æ‡≤æ‡≤°‡≤¨‡≥á‡≤ï‡≥Å",
        "‡≤∏‡≤ï‡≥ç‡≤ï‡≤∞‡≥Ü ‡≤¨‡≥Ü‡≤≤‡≥Ü ‡≤é‡≤∑‡≥ç‡≤ü‡≥Å?",
        "‡≤∏‡≥ç‡≤ü‡≤æ‡≤ï‡≥ç ‡≤≤‡≤≠‡≥ç‡≤Ø‡≤§‡≥Ü ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø",
        "‡≤®‡≤®‡≥ç‡≤® ‡≤Ü‡≤∞‡≥ç‡≤°‡≤∞‡≥ç‚Äå‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤¨‡≥á‡≤ï‡≥Å"
      ],
      'ta-IN': [
        "‡Æ®‡Ææ‡Æ©‡Øç ‡ÆÖ‡Æ∞‡Æø‡Æö‡Æø ‡ÆÜ‡Æ∞‡Øç‡Æü‡Æ∞‡Øç ‡Æ™‡Æ£‡Øç‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç",
        "‡Æö‡Æ∞‡Øç‡Æï‡Øç‡Æï‡Æ∞‡Øà ‡Æµ‡Æø‡Æ≤‡Øà ‡Æé‡Æ©‡Øç‡Æ©?",
        "‡Æ™‡Øä‡Æ∞‡ØÅ‡Æü‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Æø‡Æü‡Øà‡Æï‡Øç‡Æï‡ØÅ‡Æ§‡Ææ ‡Æé‡Æ©‡Øç‡Æ±‡ØÅ ‡Æ™‡Ææ‡Æ∞‡Øç‡Æï‡Øç‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç",
        "‡Æé‡Æ©‡Øç ‡ÆÜ‡Æ∞‡Øç‡Æü‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æâ‡Æ§‡Æµ‡Æø ‡Æ§‡Øá‡Æµ‡Øà"
      ],
      'te-IN': [
        "‡∞®‡±á‡∞®‡±Å ‡∞¨‡∞ø‡∞Ø‡±ç‡∞Ø‡∞Ç ‡∞Ü‡∞∞‡±ç‡∞°‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞®‡±Å",
        "‡∞ö‡∞ï‡±ç‡∞ï‡±Ü‡∞∞ ‡∞ß‡∞∞ ‡∞é‡∞Ç‡∞§?",
        "‡∞∏‡±ç‡∞ü‡∞æ‡∞ï‡±ç ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞â‡∞Ç‡∞¶‡∞æ ‡∞§‡∞®‡∞ø‡∞ñ‡±Ä ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø",
        "‡∞®‡∞æ ‡∞Ü‡∞∞‡±ç‡∞°‡∞∞‡±ç‚Äå‡∞ï‡±Å ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ï‡∞æ‡∞µ‡∞æ‡∞≤‡∞ø"
      ]
    };

    const responses = contextResponses[languageCode] || contextResponses['en-IN'];
    
    // Return a random but contextually appropriate response
    const randomIndex = Math.floor(Math.random() * responses.length);
    const transcription = responses[randomIndex];
    
    console.log(`üé§ Fallback transcription (${languageCode}): "${transcription}"`);
    
    return transcription;
  }

  /**
   * Get supported languages
   * @returns {Array} List of supported languages
   */
  getSupportedLanguages() {
    return [
      { code: 'en-IN', name: 'English (India)' },
      { code: 'hi-IN', name: '‡§π‡§ø‡§®‡•ç‡§¶‡•Ä (Hindi)' },
      { code: 'kn-IN', name: '‡≤ï‡≤®‡≥ç‡≤®‡≤° (Kannada)' },
      { code: 'ta-IN', name: '‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç (Tamil)' },
      { code: 'te-IN', name: '‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)' },
      { code: 'bn-IN', name: '‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ (Bengali)' },
      { code: 'mr-IN', name: '‡§Æ‡§∞‡§æ‡§†‡•Ä (Marathi)' },
      { code: 'gu-IN', name: '‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä (Gujarati)' },
      { code: 'pa-IN', name: '‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä (Punjabi)' },
      { code: 'ml-IN', name: '‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç (Malayalam)' },
    ];
  }

  /**
   * Detect language from audio
   * @param {string} audioFilePath - Path to audio file
   * @returns {Promise<string>} Detected language code
   */
  async detectLanguage(audioFilePath) {
    try {
      const audioBytes = fs.readFileSync(audioFilePath).toString('base64');

      const request = {
        audio: {
          content: audioBytes,
        },
        config: {
          encoding: 'WEBM_OPUS',
          sampleRateHertz: 48000,
          languageCodes: ['en-IN', 'hi-IN', 'kn-IN', 'ta-IN', 'te-IN', 'bn-IN'],
        },
      };

      const [response] = await this.speechClient.recognize(request);
      
      if (response.results && response.results.length > 0) {
        const result = response.results[0];
        if (result.languageCode) {
          return result.languageCode;
        }
      }

      // Default to English if detection fails
      return 'en-IN';
    } catch (error) {
      console.error('Language detection error:', error);
      return 'en-IN';
    }
  }

  /**
   * Process voice message from bot
   * @param {Object} audioBuffer - Audio buffer from voice message
   * @param {string} platform - Platform (telegram, whatsapp)
   * @returns {Promise<Object>} Transcription with metadata
   */
  async processVoiceMessage(audioBuffer, platform = 'telegram') {
    try {
      // Save buffer to temporary file
      const tempFilePath = `uploads/voice_${Date.now()}.webm`;
      fs.writeFileSync(tempFilePath, audioBuffer);

      // Detect language first
      const detectedLanguage = await this.detectLanguage(tempFilePath);

      // Transcribe with detected language
      const transcription = await this.transcribeAudio(tempFilePath, detectedLanguage);

      return {
        text: transcription,
        language: detectedLanguage,
        confidence: 0.9, // Placeholder confidence score
        platform: platform,
        timestamp: new Date().toISOString()
      };
    } catch (error) {
      console.error('Voice message processing error:', error);
      throw error;
    }
  }
}

module.exports = SpeechToTextService;
